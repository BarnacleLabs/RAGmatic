{
  "name": "simple-rag-example",
  "version": "1.0.0",
  "description": "Example project using RAGmatic, OpenAI embeddings and llm-chunk",
  "main": "index.js",
  "type": "module",
  "scripts": {
    "seed": "tsx db/seed.ts",
    "openai": "tsx pipelines/openai/index.ts",
    "openai-hyde": "tsx pipelines/openai-hyde/index.ts",
    "cohere": "tsx pipelines/cohere/index.ts",
    "ollama": "tsx pipelines/ollama/index.ts",
    "search": "tsx search.ts",
    "compare": "tsx compare.ts",
    "db:up": "docker compose -f docker-compose.yml up -d",
    "db:down": "docker compose -f docker-compose.yml down"
  },
  "keywords": [],
  "author": "",
  "license": "ISC",
  "dependencies": {
    "cohere-ai": "^7.16.0",
    "dotenv": "^16.4.7",
    "drizzle-orm": "^0.39.3",
    "llm-chunk": "^0.0.1",
    "node-fetch": "^3.3.2",
    "openai": "^4.85.0",
    "pg": "^8.13.1",
    "ragmatic": "workspace:*"
  },
  "devDependencies": {
    "@types/node": "^20.17.18",
    "tsx": "^4.19.2",
    "typescript": "^5.7.3"
  }
}
